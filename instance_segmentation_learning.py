#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOv5 å®ä¾‹åˆ†å‰²å®Œæ•´å­¦ä¹ æµç¨‹

åŒ…å«ï¼š
1. æ•°æ®é›†å‡†å¤‡å’Œä¸‹è½½
2. LabelMeå¤šè¾¹å½¢æ ‡æ³¨
3. å®ä¾‹åˆ†å‰²æ¨¡å‹è®­ç»ƒ
4. æ¨¡å‹éªŒè¯å’Œæ¨ç†
5. è¯¦ç»†çš„æ“ä½œæŒ‡å¯¼

"""

import os
import sys
import subprocess
import zipfile
import requests
from pathlib import Path
import shutil


class InstanceSegmentationLearning:
    def __init__(self):
        self.project_root = Path.cwd()
        self.datasets_dir = self.project_root / "datasets"
        self.coco128_seg_dir = self.datasets_dir / "coco128-seg"
        self.practice_dir = self.datasets_dir / "segmentation_practice"
        self.output_dir = self.datasets_dir / "yolo_seg_practice"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.datasets_dir.mkdir(exist_ok=True)
        self.practice_dir.mkdir(exist_ok=True)
        
    def print_header(self, title):
        """æ‰“å°æ ‡é¢˜"""
        print("\n" + "="*60)
        print(f"ğŸ¯ {title}")
        print("="*60)
    
    def print_step(self, step_num, title):
        """æ‰“å°æ­¥éª¤æ ‡é¢˜"""
        print(f"\nğŸ“‹ æ­¥éª¤ {step_num}: {title}")
        print("-" * 40)
    
    def check_environment(self):
        """æ£€æŸ¥ç¯å¢ƒ"""
        self.print_header("ç¯å¢ƒæ£€æŸ¥")
        
        # æ£€æŸ¥YOLOv5ç¯å¢ƒ
        if not (self.project_root / "train.py").exists():
            print("âŒ è¯·åœ¨YOLOv5é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ­¤è„šæœ¬")
            return False
        
        # æ£€æŸ¥å®ä¾‹åˆ†å‰²æ¨¡å—
        if not (self.project_root / "segment" / "train.py").exists():
            print("âŒ æœªæ‰¾åˆ°å®ä¾‹åˆ†å‰²æ¨¡å—ï¼Œè¯·ç¡®ä¿ä½¿ç”¨æ”¯æŒå®ä¾‹åˆ†å‰²çš„YOLOv5ç‰ˆæœ¬")
            return False
        
        # æ£€æŸ¥LabelMe
        try:
            import labelme
            print("âœ… LabelMe å·²å®‰è£…")
        except ImportError:
            print("âŒ LabelMe æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install labelme")
            return False
        
        print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡")
        return True
    
    def download_coco128_seg(self):
        """ä¸‹è½½COCO128-segæ•°æ®é›†"""
        self.print_step(1, "ä¸‹è½½COCO128-segæ•°æ®é›†")
        
        if self.coco128_seg_dir.exists():
            print("âœ… COCO128-segæ•°æ®é›†å·²å­˜åœ¨")
            return True
        
        zip_path = self.datasets_dir / "coco128-seg.zip"
        
        print("ğŸ“¥ æ­£åœ¨ä¸‹è½½COCO128-segæ•°æ®é›†...")
        print("ä¸‹è½½åœ°å€: https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128-seg.zip")
        
        try:
            response = requests.get('https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128-seg.zip')
            with open(zip_path, 'wb') as f:
                f.write(response.content)
            print("âœ… ä¸‹è½½å®Œæˆ")
            
            # è§£å‹
            print("ğŸ“¦ æ­£åœ¨è§£å‹æ•°æ®é›†...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(self.datasets_dir)
            print("âœ… è§£å‹å®Œæˆ")
            
            # æ¸…ç†zipæ–‡ä»¶
            zip_path.unlink()
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def prepare_practice_dataset(self):
        """å‡†å¤‡ç»ƒä¹ æ•°æ®é›†"""
        self.print_step(2, "å‡†å¤‡ç»ƒä¹ æ•°æ®é›†")
        
        # å¤åˆ¶5å¼ å›¾åƒåˆ°ç»ƒä¹ ç›®å½•
        source_images = list((self.coco128_seg_dir / "images" / "train2017").glob("*.jpg"))[:5]
        
        if not source_images:
            print("âŒ æœªæ‰¾åˆ°æºå›¾åƒ")
            return False
        
        print(f"ğŸ“ å¤åˆ¶ {len(source_images)} å¼ å›¾åƒåˆ°ç»ƒä¹ ç›®å½•...")
        
        for img_path in source_images:
            shutil.copy2(img_path, self.practice_dir / img_path.name)
            print(f"  - å¤åˆ¶: {img_path.name}")
        
        # åˆ›å»ºç±»åˆ«æ–‡ä»¶
        classes_file = self.practice_dir / "classes.txt"
        classes = [
            "person", "bicycle", "car", "motorcycle", "airplane",
            "bus", "train", "truck", "boat", "traffic light"
        ]
        
        with open(classes_file, 'w', encoding='utf-8') as f:
            for i, class_name in enumerate(classes):
                f.write(f"{i} {class_name}\n")
        
        print(f"âœ… åˆ›å»ºç±»åˆ«æ–‡ä»¶: {classes_file}")
        
        # åˆ›å»ºæ ‡æ³¨æŒ‡å—
        guide_file = self.practice_dir / "å®ä¾‹åˆ†å‰²æ ‡æ³¨æŒ‡å—.md"
        guide_content = """# å®ä¾‹åˆ†å‰²æ ‡æ³¨æŒ‡å—

## ğŸ¯ æ ‡æ³¨ç›®æ ‡
ä½¿ç”¨LabelMeä¸ºå›¾åƒä¸­çš„ç‰©ä½“åˆ›å»ºå¤šè¾¹å½¢æ ‡æ³¨ï¼Œç”¨äºå®ä¾‹åˆ†å‰²ä»»åŠ¡ã€‚

## ğŸ“‹ æ ‡æ³¨æ­¥éª¤

### 1. å¯åŠ¨LabelMe
```bash
labelme datasets/segmentation_practice
```

### 2. æ ‡æ³¨æµç¨‹
1. **é€‰æ‹©å›¾åƒ**: åœ¨LabelMeä¸­æ‰“å¼€ä¸€å¼ å›¾åƒ
2. **åˆ›å»ºå¤šè¾¹å½¢**: ç‚¹å‡» "Create Polygon" æŒ‰é’®
3. **ç»˜åˆ¶è½®å»“**: æ²¿ç€ç‰©ä½“è¾¹ç•Œç‚¹å‡»ï¼Œåˆ›å»ºå¤šè¾¹å½¢é¡¶ç‚¹
4. **é—­åˆå¤šè¾¹å½¢**: åŒå‡»æœ€åä¸€ä¸ªç‚¹æˆ–æŒ‰Enteré”®é—­åˆ
5. **è¾“å…¥ç±»åˆ«**: åœ¨å¼¹å‡ºçš„å¯¹è¯æ¡†ä¸­è¾“å…¥ç±»åˆ«åç§°
6. **ä¿å­˜æ ‡æ³¨**: æŒ‰Ctrl+Sä¿å­˜å½“å‰å›¾åƒçš„æ ‡æ³¨

### 3. æ ‡æ³¨æŠ€å·§
- **ç²¾ç¡®è¾¹ç•Œ**: å°½é‡æ²¿ç€ç‰©ä½“çš„ç²¾ç¡®è¾¹ç•Œç»˜åˆ¶
- **é¡¶ç‚¹å¯†åº¦**: åœ¨æ›²çº¿å¤„å¢åŠ æ›´å¤šé¡¶ç‚¹
- **ç±»åˆ«ä¸€è‡´**: ä½¿ç”¨classes.txtä¸­çš„æ ‡å‡†ç±»åˆ«åç§°
- **å®Œæ•´æ ‡æ³¨**: ç¡®ä¿æ‰€æœ‰ç›®æ ‡ç‰©ä½“éƒ½è¢«æ ‡æ³¨

### 4. ä¿å­˜æ ¼å¼
- æ ‡æ³¨æ–‡ä»¶ä¿å­˜ä¸ºJSONæ ¼å¼
- æ–‡ä»¶åä¸å›¾åƒæ–‡ä»¶åå¯¹åº”
- æ¯ä¸ªç‰©ä½“åŒ…å«å¤šè¾¹å½¢åæ ‡å’Œç±»åˆ«ä¿¡æ¯

## âš ï¸ æ³¨æ„äº‹é¡¹
- æ ‡æ³¨è´¨é‡ç›´æ¥å½±å“æ¨¡å‹æ€§èƒ½
- ä¿æŒè€å¿ƒï¼Œç²¾ç¡®æ ‡æ³¨
- å¯ä»¥å¤šæ¬¡è°ƒæ•´å¤šè¾¹å½¢å½¢çŠ¶
- å»ºè®®å…ˆæ ‡æ³¨ç®€å•ç‰©ä½“ï¼Œå†æ ‡æ³¨å¤æ‚ç‰©ä½“
"""
        
        with open(guide_file, 'w', encoding='utf-8') as f:
            f.write(guide_content)
        
        print(f"âœ… åˆ›å»ºæ ‡æ³¨æŒ‡å—: {guide_file}")
        return True
    
    def show_dataset_info(self):
        """æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯"""
        self.print_step(3, "æ•°æ®é›†ä¿¡æ¯")
        
        print("ğŸ“Š COCO128-segæ•°æ®é›†:")
        if self.coco128_seg_dir.exists():
            image_count = len(list((self.coco128_seg_dir / "images" / "train2017").glob("*.jpg")))
            label_count = len(list((self.coco128_seg_dir / "labels" / "train2017").glob("*.txt")))
            print(f"  - å›¾åƒæ•°é‡: {image_count}")
            print(f"  - æ ‡ç­¾æ•°é‡: {label_count}")
            print(f"  - ç±»åˆ«æ•°é‡: 80ä¸ªæ ‡å‡†ç±»åˆ«")
            print(f"  - æ ‡ç­¾æ ¼å¼: å®ä¾‹åˆ†å‰²å¤šè¾¹å½¢åæ ‡")
        else:
            print("  - çŠ¶æ€: æœªä¸‹è½½")
        
        print(f"\nğŸ“ ç»ƒä¹ æ•°æ®é›†:")
        if self.practice_dir.exists():
            image_files = list(self.practice_dir.glob("*.jpg"))
            json_files = list(self.practice_dir.glob("*.json"))
            print(f"  - å›¾åƒæ•°é‡: {len(image_files)}")
            print(f"  - å·²æ ‡æ³¨æ•°é‡: {len(json_files)}")
            print(f"  - çŠ¶æ€: {'âœ… å‡†å¤‡å°±ç»ª' if len(json_files) == 5 else 'â³ éœ€è¦æ ‡æ³¨'}")
        else:
            print("  - çŠ¶æ€: æœªåˆ›å»º")
    
    def start_labelme_annotation(self):
        """å¯åŠ¨LabelMeè¿›è¡Œæ ‡æ³¨"""
        self.print_step(4, "å¯åŠ¨LabelMeè¿›è¡Œæ ‡æ³¨")
        
        if not self.practice_dir.exists():
            print("âŒ ç»ƒä¹ æ•°æ®é›†æœªå‡†å¤‡ï¼Œè¯·å…ˆè¿è¡Œæ­¥éª¤2")
            return False
        
        print("ğŸš€ æ­£åœ¨å¯åŠ¨LabelMe...")
        print(f"æ ‡æ³¨ç›®å½•: {self.practice_dir.absolute()}")
        
        print("\nğŸ“‹ è¯¦ç»†æ ‡æ³¨æ­¥éª¤:")
        print("1. LabelMeå°†è‡ªåŠ¨æ‰“å¼€ç»ƒä¹ ç›®å½•")
        print("2. é€‰æ‹©ä¸€å¼ å›¾åƒå¼€å§‹æ ‡æ³¨")
        print("3. ç‚¹å‡» 'Create Polygon' åˆ›å»ºå¤šè¾¹å½¢")
        print("4. æ²¿ç€ç‰©ä½“è¾¹ç•Œç‚¹å‡»ï¼Œåˆ›å»ºå¤šè¾¹å½¢é¡¶ç‚¹")
        print("5. åŒå‡»æœ€åä¸€ä¸ªç‚¹æˆ–æŒ‰Enteré”®é—­åˆå¤šè¾¹å½¢")
        print("6. è¾“å…¥ç±»åˆ«åç§° (å‚è€ƒclasses.txt)")
        print("7. æŒ‰Ctrl+Sä¿å­˜æ ‡æ³¨")
        print("8. é‡å¤æ­¥éª¤3-7ï¼Œæ ‡æ³¨æ‰€æœ‰ç›®æ ‡ç‰©ä½“")
        print("9. é€‰æ‹©ä¸‹ä¸€å¼ å›¾åƒç»§ç»­æ ‡æ³¨")
        
        print(f"\nğŸ’¡ é‡è¦æç¤º:")
        print("- ä½¿ç”¨å¤šè¾¹å½¢æ ‡æ³¨ï¼Œä¸æ˜¯çŸ©å½¢æ¡†")
        print("- æ²¿ç€ç‰©ä½“çš„ç²¾ç¡®è¾¹ç•Œç»˜åˆ¶")
        print("- åœ¨æ›²çº¿å¤„å¢åŠ æ›´å¤šé¡¶ç‚¹")
        print("- ç¡®ä¿å¤šè¾¹å½¢å®Œå…¨é—­åˆ")
        
        try:
            subprocess.run(["labelme", str(self.practice_dir)], check=True)
            print("\nâœ… LabelMeå·²å…³é—­")
            print("è¯·æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ˜¯å¦å·²ä¿å­˜")
            
        except subprocess.CalledProcessError:
            print("âŒ å¯åŠ¨LabelMeå¤±è´¥")
            print("è¯·æ‰‹åŠ¨è¿è¡Œ: labelme datasets/segmentation_practice")
        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°LabelMeï¼Œè¯·å…ˆå®‰è£…: pip install labelme")
    
    def convert_to_yolo_seg(self):
        """è½¬æ¢ä¸ºYOLOå®ä¾‹åˆ†å‰²æ ¼å¼"""
        self.print_step(5, "è½¬æ¢ä¸ºYOLOå®ä¾‹åˆ†å‰²æ ¼å¼")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡æ³¨æ–‡ä»¶
        json_files = list(self.practice_dir.glob("*.json"))
        if not json_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ ‡æ³¨")
            return False
        
        print(f"æ‰¾åˆ° {len(json_files)} ä¸ªæ ‡æ³¨æ–‡ä»¶")
        
        # ä½¿ç”¨ä¸“é—¨çš„è½¬æ¢è„šæœ¬
        print("ğŸ”„ ä½¿ç”¨ labelme2yolo_seg.py è¿›è¡Œè½¬æ¢...")
        
        try:
            cmd = [
                sys.executable, "labelme2yolo_seg.py",
                "--input_dir", str(self.practice_dir),
                "--output_dir", str(self.output_dir),
                "--classes", str(self.practice_dir / "classes.txt")
            ]
            
            print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print("âœ… è½¬æ¢å®Œæˆ!")
            print(result.stdout)
            
            return True
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
            return False
    
    def train_segmentation_model(self):
        """è®­ç»ƒå®ä¾‹åˆ†å‰²æ¨¡å‹"""
        self.print_step(6, "è®­ç»ƒå®ä¾‹åˆ†å‰²æ¨¡å‹")
        
        # æ£€æŸ¥æ•°æ®é›†
        dataset_yaml = self.output_dir / "dataset.yaml"
        if not dataset_yaml.exists():
            print("âŒ æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆæ•°æ®è½¬æ¢")
            return False
        
        print("ğŸš€ å¼€å§‹è®­ç»ƒå®ä¾‹åˆ†å‰²æ¨¡å‹...")
        print("æ³¨æ„: å®ä¾‹åˆ†å‰²è®­ç»ƒéœ€è¦æ›´å¤šæ—¶é—´å’Œè®¡ç®—èµ„æº")
        
        # è®­ç»ƒå‘½ä»¤
        cmd = [
            sys.executable, "segment/train.py",
            "--data", str(dataset_yaml),
            "--weights", "yolov5s-seg.pt",  # ä½¿ç”¨å®ä¾‹åˆ†å‰²é¢„è®­ç»ƒæƒé‡
            "--img", "640",
            "--epochs", "50",  # å®ä¾‹åˆ†å‰²éœ€è¦æ›´å¤šepochs
            "--batch-size", "4",  # å‡å°æ‰¹æ¬¡å¤§å°
            "--project", "segmentation_training",
            "--name", "practice_model"
        ]
        
        print(f"è®­ç»ƒå‘½ä»¤: {' '.join(cmd)}")
        print("\nâ³ è®­ç»ƒå¼€å§‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        print("ğŸ’¡ æç¤º:")
        print("- å®ä¾‹åˆ†å‰²è®­ç»ƒæ¯”ç›®æ ‡æ£€æµ‹æ…¢")
        print("- ä¼šæ˜¾ç¤ºåˆ†å‰²æŸå¤±å’Œè¾¹ç•Œæ¡†æŸå¤±")
        print("- è®­ç»ƒç»“æœä¿å­˜åœ¨ runs/train/segmentation_training/")
        
        try:
            result = subprocess.run(cmd, check=True)
            print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
            
            # æ˜¾ç¤ºç»“æœä½ç½®
            result_dir = Path("runs/train/segmentation_training/practice_model")
            if result_dir.exists():
                print(f"\nğŸ“ è®­ç»ƒç»“æœä¿å­˜åœ¨: {result_dir}")
                
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
            print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶é‡è¯•")
            return False
        
        return True
    
    def validate_model(self):
        """éªŒè¯æ¨¡å‹æ€§èƒ½"""
        self.print_step(7, "éªŒè¯æ¨¡å‹æ€§èƒ½")
        
        # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æƒé‡
        weights_dir = Path("runs/train/segmentation_training/practice_model/weights")
        if not weights_dir.exists():
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœï¼Œè¯·å…ˆå®Œæˆè®­ç»ƒ")
            return False
        
        best_weights = weights_dir / "best.pt"
        if not best_weights.exists():
            print("âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æƒé‡")
            return False
        
        print(f"âœ… æ‰¾åˆ°æœ€ä½³æ¨¡å‹: {best_weights}")
        
        # éªŒè¯å‘½ä»¤
        dataset_yaml = self.output_dir / "dataset.yaml"
        cmd = [
            sys.executable, "segment/val.py",
            "--weights", str(best_weights),
            "--data", str(dataset_yaml),
            "--img", "640"
        ]
        
        print(f"éªŒè¯å‘½ä»¤: {' '.join(cmd)}")
        print("\nâ³ å¼€å§‹éªŒè¯...")
        
        try:
            subprocess.run(cmd, check=True)
            print("\nâœ… éªŒè¯å®Œæˆ!")
            print("æŸ¥çœ‹éªŒè¯ç»“æœäº†è§£æ¨¡å‹æ€§èƒ½")
            
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ éªŒè¯å¤±è´¥: {e}")
    
    def test_inference(self):
        """æµ‹è¯•æ¨¡å‹æ¨ç†"""
        self.print_step(8, "æµ‹è¯•æ¨¡å‹æ¨ç†")
        
        # æŸ¥æ‰¾æœ€ä½³æ¨¡å‹æƒé‡
        weights_dir = Path("runs/train/segmentation_training/practice_model/weights")
        if not weights_dir.exists():
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒç»“æœï¼Œè¯·å…ˆå®Œæˆè®­ç»ƒ")
            return False
        
        best_weights = weights_dir / "best.pt"
        if not best_weights.exists():
            print("âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æƒé‡")
            return False
        
        print(f"âœ… ä½¿ç”¨æ¨¡å‹: {best_weights}")
        
        # é€‰æ‹©æµ‹è¯•å›¾åƒ
        test_image = self.practice_dir / "000000000009.jpg"
        if not test_image.exists():
            print(f"âŒ æµ‹è¯•å›¾åƒä¸å­˜åœ¨: {test_image}")
            return False
        
        # æ¨ç†å‘½ä»¤
        cmd = [
            sys.executable, "segment/predict.py",
            "--weights", str(best_weights),
            "--source", str(test_image),
            "--project", "segmentation_inference",
            "--name", "practice_test"
        ]
        
        print(f"æ¨ç†å‘½ä»¤: {' '.join(cmd)}")
        print("\nâ³ å¼€å§‹æ¨ç†...")
        
        try:
            subprocess.run(cmd, check=True)
            print("\nâœ… æ¨ç†å®Œæˆ!")
            
            # æ˜¾ç¤ºç»“æœä½ç½®
            result_dir = Path("runs/predict/segmentation_inference/practice_test")
            if result_dir.exists():
                print(f"\nğŸ“ æ¨ç†ç»“æœä¿å­˜åœ¨: {result_dir}")
                print("æŸ¥çœ‹ç”Ÿæˆçš„å›¾åƒï¼Œå¯¹æ¯”åŸå§‹æ ‡æ³¨å’Œé¢„æµ‹ç»“æœ")
                
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ æ¨ç†å¤±è´¥: {e}")
    
    def show_complete_workflow(self):
        """æ˜¾ç¤ºå®Œæ•´å·¥ä½œæµç¨‹"""
        self.print_header("å®Œæ•´å·¥ä½œæµç¨‹æ€»ç»“")
        
        workflow = """
ğŸ¯ å®ä¾‹åˆ†å‰²å®Œæ•´å­¦ä¹ æµç¨‹:

1. ğŸ“¥ æ•°æ®é›†å‡†å¤‡
   - ä¸‹è½½COCO128-segå®˜æ–¹æ•°æ®é›†
   - å‡†å¤‡LabelMeç»ƒä¹ æ•°æ®é›†
   - äº†è§£å®ä¾‹åˆ†å‰²æ ‡ç­¾æ ¼å¼

2. ğŸ·ï¸ æ•°æ®æ ‡æ³¨ (LabelMe)
   - ä½¿ç”¨å¤šè¾¹å½¢æ ‡æ³¨å·¥å…·
   - æ²¿ç€ç‰©ä½“è¾¹ç•Œç²¾ç¡®ç»˜åˆ¶
   - æ ‡æ³¨5å¼ ç»ƒä¹ å›¾åƒ

3. ğŸ”„ æ ¼å¼è½¬æ¢
   - å°†LabelMe JSONè½¬æ¢ä¸ºYOLOæ ¼å¼
   - åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
   - ç”Ÿæˆdataset.yamlé…ç½®æ–‡ä»¶

4. ğŸš€ æ¨¡å‹è®­ç»ƒ
   - ä½¿ç”¨yolov5s-seg.pté¢„è®­ç»ƒæƒé‡
   - è®­ç»ƒ50ä¸ªepochs
   - ç›‘æ§åˆ†å‰²æŸå¤±å’Œè¾¹ç•Œæ¡†æŸå¤±

5. ğŸ” æ¨¡å‹éªŒè¯
   - åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ€§èƒ½
   - æŸ¥çœ‹mAPã€åˆ†å‰²ç²¾åº¦ç­‰æŒ‡æ ‡
   - åˆ†ææ¨¡å‹ä¼˜ç¼ºç‚¹

6. ğŸ¯ æ¨¡å‹æ¨ç†
   - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
   - ç”Ÿæˆåˆ†å‰²æ©ç å’Œè¾¹ç•Œæ¡†
   - å¯¹æ¯”é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡æ³¨

ğŸ’¡ å­¦ä¹ è¦ç‚¹:
- å®ä¾‹åˆ†å‰²æ¯”ç›®æ ‡æ£€æµ‹æ›´å¤æ‚
- å¤šè¾¹å½¢æ ‡æ³¨éœ€è¦æ›´é«˜çš„ç²¾åº¦
- è®­ç»ƒæ—¶é—´æ›´é•¿ï¼Œéœ€è¦æ›´å¤šæ•°æ®
- ç»“æœåŒ…å«åˆ†å‰²æ©ç å’Œæ£€æµ‹æ¡†
"""
        
        print(workflow)
    
    def run_interactive_mode(self):
        """è¿è¡Œäº¤äº’æ¨¡å¼"""
        self.print_header("å®ä¾‹åˆ†å‰²å­¦ä¹ äº¤äº’æ¨¡å¼")
        
        while True:
            print("\nğŸ“‹ è¯·é€‰æ‹©æ“ä½œ:")
            print("1. ğŸ” æ£€æŸ¥ç¯å¢ƒ")
            print("2. ğŸ“¥ ä¸‹è½½COCO128-segæ•°æ®é›†")
            print("3. ğŸ“ å‡†å¤‡ç»ƒä¹ æ•°æ®é›†")
            print("4. ğŸ“Š æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯")
            print("5. ğŸ·ï¸ å¯åŠ¨LabelMeè¿›è¡Œæ ‡æ³¨")
            print("6. ğŸ”„ è½¬æ¢ä¸ºYOLOæ ¼å¼")
            print("7. ğŸš€ è®­ç»ƒå®ä¾‹åˆ†å‰²æ¨¡å‹")
            print("8. ğŸ” éªŒè¯æ¨¡å‹æ€§èƒ½")
            print("9. ğŸ¯ æµ‹è¯•æ¨¡å‹æ¨ç†")
            print("10. ğŸ“‹ æŸ¥çœ‹å®Œæ•´å·¥ä½œæµç¨‹")
            print("11. ğŸšª é€€å‡º")
            
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-11): ").strip()
                
                if choice == '1':
                    self.check_environment()
                elif choice == '2':
                    self.download_coco128_seg()
                elif choice == '3':
                    self.prepare_practice_dataset()
                elif choice == '4':
                    self.show_dataset_info()
                elif choice == '5':
                    self.start_labelme_annotation()
                elif choice == '6':
                    self.convert_to_yolo_seg()
                elif choice == '7':
                    self.train_segmentation_model()
                elif choice == '8':
                    self.validate_model()
                elif choice == '9':
                    self.test_inference()
                elif choice == '10':
                    self.show_complete_workflow()
                elif choice == '11':
                    print("ğŸ‘‹ å†è§ï¼ç¥æ‚¨å­¦ä¹ æ„‰å¿«ï¼")
                    break
                else:
                    print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-11")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ YOLOv5 å®ä¾‹åˆ†å‰²å®Œæ•´å­¦ä¹ æµç¨‹")
    print("=" * 60)
    
    learner = InstanceSegmentationLearning()
    
    # æ£€æŸ¥ç¯å¢ƒ
    if not learner.check_environment():
        return
    
    # è¿è¡Œäº¤äº’æ¨¡å¼
    learner.run_interactive_mode()


if __name__ == "__main__":
    main() 